!git clone https://github.com/maichi98/PythonM2-jour4.git
%cd PythonM2-jour4/









































import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

# Patient name : 
patient_name = "BraTS19_CBICA_AAG_1"

# Paths to MRI scans and the masks data : 
dict_mri_paths = {
    imaging: fr"example BraTS patients/{patient_name}/{patient_name}_{imaging}.nii.gz" 
    for imaging in ["t1", "t1ce", "t2", "flair"]
}

path_seg = fr"example BraTS patients/{patient_name}/{patient_name}_seg.nii.gz"     # mask file

# Load the images using nibabel : 
dict_mri_images = {
    imaging: nib.load(dict_mri_paths[imaging]).get_fdata()
    for imaging in ["t1", "t1ce", "t2", "flair"]
}

img_seg = nib.load(path_seg).get_fdata()

# the Slice Index : 
slice_idx = 55  # Extracting the middle axial slice



# Plot the MRI slices and the Labels data : 
fig, axes = plt.subplots(1, 5, figsize=(18, 4))

for i, imaging in enumerate(["t1", "t1ce", "t2", "flair"]):

    axes[i].imshow(dict_mri_images[imaging][:, :, slice_idx].T, cmap="gray")
    axes[i].set_title(imaging.upper())

axes[4].imshow(img_seg[:, :, slice_idx].T, cmap="gray")
axes[4].set_title("Labels")

plt.suptitle("BraTS MRI Modalities - Axial View", fontsize=15)
plt.show()



# Plot the MRI slices with the Labels overlayed on the mri image : 
fig, axes = plt.subplots(1, 4, figsize=(16, 4))

for i, imaging in enumerate(["t1", "t1ce", "t2", "flair"]):

    axes[i].imshow(dict_mri_images[imaging][:, :, slice_idx].T, cmap="gray")
    axes[i].imshow(img_seg[:, :, slice_idx].T, cmap="jet", alpha=0.2)
    axes[i].set_title(imaging.upper())

plt.suptitle("BraTS MRI Modalities - Axial View", fontsize=15)
plt.show()






























from sklearn.model_selection import train_test_split
import random
import os


# List of slice names for both training and test : 
list_original_train_slices = os.listdir("data/train/images")
list_test_slices = os.listdir("data/test/images")

# Extract patients IDs that correspond to the training set : 
list_original_train_ids = list(set(
    [slice_name.split("_")[1] for slice_name in list_original_train_slices]
))

# Split the training patients into training and validation sets (e.g., 80%, 20%)
# random_state=42 ensures that the split is always the same. This is useful for reproducibility.
list_train_ids, list_val_ids = train_test_split(list_original_train_ids, test_size=0.2, random_state=42)

list_train_slices = [slice_name for slice_name
                     in list_original_train_slices
                     if slice_name.split("_")[1] in list_train_ids]

list_val_slices = [slice_name for slice_name
                   in list_original_train_slices
                   if slice_name.split("_")[1] in list_val_ids]

print(fr"Number of slices in the training set : {len(list_train_slices)}")
print(fr"Number of slices in the validation set : {len(list_val_slices)}")
print(fr"Number of slices in the testing set : {len(list_test_slices)}")









import torch
import torch.nn as nn
import torch.nn.functional as F

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(UNet, self).__init__()

        # Encoder (Downsampling)
        self.enc1 = self.conv_block(in_channels, 32)
        self.enc2 = self.conv_block(32, 64)
        self.enc3 = self.conv_block(64, 128)
        self.enc4 = self.conv_block(128, 256)
        self.enc5 = self.conv_block(256, 320)

        # Bottleneck
        self.bottleneck = self.conv_block(320, 320)

        # Decoder (Upsampling)
        self.up1 = nn.ConvTranspose2d(320, 256, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(512, 256)  # (256+256=512)

        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 128)  # (128+128=256)

        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(128, 64)  # (64+64=128)

        self.up4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(64, 32)  # (32+32=64)

        # Output layer
        self.out = nn.Conv2d(32, out_channels, kernel_size=1)

        # MaxPooling
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        # Encoding Path
        x1 = self.enc1(x)
        x2 = self.enc2(self.maxpool(x1))
        x3 = self.enc3(self.maxpool(x2))
        x4 = self.enc4(self.maxpool(x3))
        x5 = self.enc5(self.maxpool(x4))

        # Bottleneck
        x = self.bottleneck(x5)

        # Decoding Path
        x = self.up1(x)
        x = torch.cat((x, x4), dim=1)  # (256+256=512)
        x = self.dec1(x)

        x = self.up2(x)
        x = torch.cat((x, x3), dim=1)  # (128+128=256)
        x = self.dec2(x)

        x = self.up3(x)
        x = torch.cat((x, x2), dim=1)  # (64+64=128)
        x = self.dec3(x)

        x = self.up4(x)
        x = torch.cat((x, x1), dim=1)  # (32+32=64)
        x = self.dec4(x)

        # Output Layer: Return raw logits (do not apply sigmoid here)
        return self.out(x)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),  # Optional: Batch Norm for stability
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),  # Optional: Batch Norm for stability
            nn.ReLU(inplace=True)
        )



# Create U-Net model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = UNet(in_channels=1, out_channels=1).to(device)



# Print Model Summary
from torchsummary import summary
summary(model, input_size=(1, 240, 240))



import torch.optim as optim

# Define the loss function
criterion = nn.BCEWithLogitsLoss()

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=1e-3)



import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import nibabel as nib
import albumentations as A

class BratsDataset(Dataset):
    def __init__(self, dir_data, list_slices, transform=None):

        self.dir_data = dir_data
        self.list_slices = list_slices
        self.transform= transform

    def __len__(self):
        return len(self.list_slices)

    def __getitem__(self, idx):
        slice_filename = self.list_slices[idx]
        path_image = os.path.join(self.dir_data, "images", slice_filename)
        path_mask = os.path.join(self.dir_data, "masks", slice_filename) 

        # Load the NIfTI files
        image_nii = nib.load(path_image)
        image_data = image_nii.get_fdata().astype(np.float32)  

        mask_nii = nib.load(path_mask)
        mask_data = mask_nii.get_fdata().astype(np.float32)    

        # Add a channel dimension: shape becomes [1, H, W]
        image_data = np.expand_dims(image_data, axis=0)
        mask_data = np.expand_dims(mask_data, axis=0)

        # Convert the NumPy arrays to PyTorch tensors
        image_tensor = torch.tensor(image_data, dtype=torch.float32)
        mask_tensor = torch.tensor(mask_data, dtype=torch.float32)

        # Optionally, apply any additional transforms (these transforms should work on tensors)
        if self.transform:
            augmented = self.transform(image=image_data, mask=mask_data)
            image_data = augmented['image']
            mask_data = augmented['mask']

        # Since the mask is already binary, no additional thresholding is necessary.
        return {
            "slice_name": slice_filename.removesuffix(".nii.gz"),
            "image": image_tensor,
            "mask": mask_tensor
        }
        


dir_train = "data/train"  

train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
])



# Visualize data augmentation 

## Load an a slice from a patient as an example : 
example = "patient_001_0100.nii.gz"
path_image, path_mask = f"data/train/images/{example}", f"data/train/masks/{example}"
image_nii, mask_nii = nib.load(path_image), nib.load(path_mask)
image = image_nii.get_fdata().astype(np.float32)  
mask = mask_nii.get_fdata().astype(np.float32)  


# Define individual transformations with p=1.0 for visualization
hflip = A.HorizontalFlip(p=1.0)      # Always flip horizontally
vflip = A.VerticalFlip(p=1.0)        # Always flip vertically
rotate90 = A.RandomRotate90(p=1.0)     # Always rotate by a multiple of 90 degrees

# # Apply each transformation individually
hflip_aug = hflip(image=image, mask=mask)
img_hflip, mask_hflip = hflip_aug["image"], hflip_aug["mask"]

vflip_aug = vflip(image=image, mask=mask)
img_vflip, mask_vflip = vflip_aug["image"], vflip_aug["mask"] 

rotate90_aug = rotate90(image=image, mask=mask)
img_rotate90, mask_rotate90 = rotate90_aug["image"], rotate90_aug["mask"] 

# Apply the composed pipeline (output will vary because of randomness)
pipeline_aug = train_transform(image=image, mask=mask)
img_pipeline, mask_pipeline = pipeline_aug["image"], pipeline_aug["mask"] 

# Visualize the results with overlayed masks
fig, axes = plt.subplots(2, 3, figsize=(12, 8))
axes = axes.flatten()

axes[0].imshow(image.T, cmap="gray")
axes[0].imshow(mask.T, cmap="jet", alpha=0.5)
axes[0].set_title("Original Image")

axes[1].imshow(img_hflip.T, cmap="gray")
axes[1].imshow(mask_hflip.T, cmap="jet", alpha=0.5)
axes[1].set_title("Horizontal Flip (p=1.0)")

axes[2].imshow(img_vflip.T, cmap="gray")
axes[2].imshow(mask_vflip.T, cmap="jet", alpha=0.5)
axes[2].set_title("Vertical Flip (p=1.0)")

axes[3].imshow(img_rotate90.T, cmap="gray")
axes[3].imshow(mask_rotate90.T, cmap="jet", alpha=0.5)
axes[3].set_title("Random Rotate90 (p=1.0)")

axes[4].imshow(img_pipeline.T, cmap="gray")
axes[4].imshow(mask_pipeline.T, cmap="jet", alpha=0.5)
axes[4].set_title("Pipeline Output (p=0.5)")

# Hide the unused subplot
axes[5].axis("off")

plt.tight_layout()
plt.show()



# Create dataset instances
train_dataset = BratsDataset(
    dir_data = dir_train,
    list_slices=list_train_slices, 
    transform=train_transform
)

val_dataset = BratsDataset(
    dir_data = dir_train,
    list_slices=list_val_slices,  
    transform=None
)



# Create DataLoader objects
train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)
val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)
    


import tqdm as tqdm

num_epochs = 1

# Placeholders for loss history
train_loss_history = []
val_loss_history = []

# Initialize best validation loss with a large number
best_val_loss = float('inf')

for epoch in range(num_epochs):
    # --------------------------
    # Training Phase
    # --------------------------
    model.train()  # Set model to training mode
    train_losses = []
    
    with tqdm.tqdm(total=len(train_dataloader), desc=f"Epoch {epoch + 1}/{num_epochs}", unit="batch") as pbar:
        
        for batch in train_dataloader:
            # Move data to the device
            inputs, labels = batch["image"].to(device), batch["mask"].to(device)
            
            # Zero the parameter gradients
            optimizer.zero_grad()
            
            # Forward pass
            outputs = model(inputs)
            
            # Compute loss
            loss = criterion(outputs, labels)
            
            # Backward pass and optimize
            loss.backward()
            optimizer.step()
            
            # Save the loss and update progress bar
            train_losses.append(loss.item())
            pbar.update(1)
            pbar.set_postfix({"training_loss": loss.item()})
    
    # Compute average training loss for the epoch
    avg_train_loss = sum(train_losses) / len(train_losses)
    train_loss_history.append(avg_train_loss)
    
    # --------------------------
    # Validation Phase
    # --------------------------
    print("Validation in progress ...")
    model.eval()  # Set model to evaluation mode
    val_losses = []
    
    # Disable gradient computation for validation
    with torch.no_grad():
        with tqdm.tqdm(total=len(val_dataloader), desc=f"Validation Epoch {epoch + 1}/{num_epochs}", unit="batch") as pbar_val:
            for batch in val_dataloader:
                # Move data to the device
                inputs, labels = batch["image"].to(device), batch["mask"].to(device)
                
                # Forward pass
                outputs = model(inputs)
                
                # Compute loss
                loss = criterion(outputs, labels)
                val_losses.append(loss.item())
                
                pbar_val.update(1)
                pbar_val.set_postfix({"validation_loss": loss.item()})
    
    # Compute average validation loss for the epoch
    avg_val_loss = sum(val_losses) / len(val_losses)
    val_loss_history.append(avg_val_loss)
    
    print(f"Epoch {epoch + 1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}")
    
    # --------------------------
    # Save Model Checkpoints
    # --------------------------
    # Save the last model after each epoch
    torch.save(model.state_dict(), "last_model.pth")
    
    # If the current validation loss is the best so far, save the model as the best model
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), "best_model.pth")
        print(f"Best model updated at epoch {epoch + 1} with validation loss {avg_val_loss:.4f}")
        


# Create the test dataset and dataloader
dir_test = "data/test"

test_dataset = BratsDataset(
    dir_data=dir_test,
    list_slices=list_test_slices,  
    transform=None
)

test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)



def compute_dice(outputs, targets, eps=1e-6):

    # Convert the logits to probability using sigmoid
    outputs = torch.sigmoid(outputs)
    
    # Convert probabilities to binary masks 
    outputs = (outputs > 0.5).float()
    targets = targets.float()
    
    # Compute intersection and union per sample
    intersection = (outputs * targets).sum(dim=(1, 2))
    union = outputs.sum(dim=(1, 2)) + targets.sum(dim=(1, 2))
    
    # Compute dice coefficient for each sample and then average over the batch
    dice = (2.0 * intersection + eps) / (union + eps)
    return dice.mean()
    


import pandas as pd


eps = 1e-6

model.eval()  
test_dice_scores = []

df_dice = pd.DataFrame(columns=["slice_name", "patient", "slice", "union", "intersection", "dice"])


with torch.no_grad():
    for batch in test_dataloader:

        slice_name = batch["slice_name"][0]
        inputs, labels = batch["image"].to(device), batch["mask"].to(device)
        
        # Forward pass
        outputs = model(inputs)
        # Squeeze out the channel dimension: now (B, H, W)
        outputs = outputs.squeeze(1)
        labels = labels.squeeze(1)

        # Convert the logits to probability using sigmoid
        outputs = torch.sigmoid(outputs)
        outputs = (outputs > 0.5).float()
        labels = labels.float()

        intersection = (outputs * labels).sum(dim=(1, 2))
        union = outputs.sum(dim=(1, 2)) + labels.sum(dim=(1, 2))

        intersection, union = intersection.item(), union.item()
        
        # Compute Dice coefficient for this batch (or single sample, if batch_size==1)
        dice = ((2.0 * intersection + eps) / (union + eps))

        print(fr"Slice name : {slice_name} -- GT volume: {labels.sum().item()}mm^3 -- Dice score: {dice * 100:.2f} %")
        df_dice.loc[len(df_dice)] = {
            "slice_name": slice_name, "patient": slice_name.split("_")[1], "slice": slice_name.split("_")[2],
            "union": union, "mask": mask, "dice": dice
        }

avg_test_dice = sum(test_dice_scores) / len(test_dice_scores)
print(f"\nmean Test Dice on all slices: {avg_test_dice:.4f}")






# ------------------------------
# Visualize a few examples (only those with tumors)
# ------------------------------
num_examples = min(3, len(tumor_examples))

fig, axes = plt.subplots(num_examples, 3, figsize=(15, 5*num_examples))

# If only one example, ensure axes is 2D
if num_examples == 1:
    axes = np.expand_dims(axes, axis=0)
    
for i in range(num_examples):
    inp, pred, gt, dice = tumor_examples[i]
    # Assume batch size is >= 1; take the first sample in the batch.
    # Convert to numpy arrays for visualization.
    img = inp[0, 0, :, :].numpy()            # Original image
    gt_mask = gt[0].numpy()                   # Ground truth mask
    # Threshold prediction (it might still be probabilities)
    pred_mask = (pred[0] > 0.5).float().numpy()
    
    # Original image
    axes[i, 0].imshow(img.T, cmap="gray")
    axes[i, 0].set_title("Original Image")
    axes[i, 0].axis("off")
    
    # Ground truth overlay
    axes[i, 1].imshow(img.T, cmap="gray")
    axes[i, 1].imshow(gt_mask.T, cmap="jet", alpha=0.5)
    axes[i, 1].set_title("Ground Truth")
    axes[i, 1].axis("off")
    
    # Prediction overlay with Dice score
    axes[i, 2].imshow(img.T, cmap="gray")
    axes[i, 2].imshow(pred_mask.T, cmap="jet", alpha=0.5)
    axes[i, 2].set_title(fr"Prediction (Dice: {dice:.4f})")
    axes[i, 2].axis("off")
    
plt.tight_layout()
plt.show()



from scipy.spatial.distance import directed_hausdorff


def hausdorff_distance(outputs, targets):

    if torch.is_tensor(outputs):
        outputs = outputs.cpu().numpy()
    if torch.is_tensor(targets):
        targets = targets.cpu().numpy()
        
    # Get coordinates where mask==1
    coords_outputs = np.argwhere(outputs > 0)
    coords_targets = np.argwhere(targets > 0)
    
    # If one of the masks is empty, return nan (or a large number)
    if len(coords_outputs) == 0 or len(coords_targets) == 0:
        return np.nan
    
    d1 = directed_hausdorff(coords_outputs, coords_targets)[0]
    d2 = directed_hausdorff(coords_targets, coords_outputs)[0]
    return max(d1, d2)
    


# Load the trained model : 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.load_state_dict(torch.load("best_model_12022025.pth", map_location=device))
model.to(device)
model.eval()



model.eval()  
test_dice_scores = []
tumor_examples = []  # to save examples for visualization

with torch.no_grad():
    for inputs, labels in test_dataloader:

        inputs, labels = inputs.to(device), labels.to(device)
        
        # Forward pass
        outputs = model(inputs)
        # Squeeze out the channel dimension: now (B, H, W)
        outputs = outputs.squeeze(1)
        labels = labels.squeeze(1)
        
        # Check if the ground truth has any tumor pixels
        if labels.sum() > 0:
            # Compute Dice coefficient for this batch (or single sample, if batch_size==1)
            dice = compute_dice(outputs, labels)
            print(fr"GT volume: {labels.sum().item()} -- Dice score: {dice:.4f}")
            test_dice_scores.append(dice)
            
            # Save example for visualization (convert to cpu for plotting)
            # We'll save the first image in the batch
            tumor_examples.append((inputs.cpu(), outputs.cpu(), labels.cpu(), dice))
        else:
            print("No tumor in slice, skipping dice calculation.")

# Compute average Dice over all tumor-containing test slices
avg_test_dice = sum(test_dice_scores) / len(test_dice_scores)
print(f"\nTest Dice on tumor slices: {avg_test_dice:.4f}")



# ------------------------------
# Visualize a few examples (only those with tumors)
# ------------------------------
num_examples = min(3, len(tumor_examples))

fig, axes = plt.subplots(num_examples, 3, figsize=(15, 5*num_examples))

# If only one example, ensure axes is 2D
if num_examples == 1:
    axes = np.expand_dims(axes, axis=0)
    
for i in range(num_examples):
    inp, pred, gt, dice = tumor_examples[i]
    # Assume batch size is >= 1; take the first sample in the batch.
    # Convert to numpy arrays for visualization.
    img = inp[0, 0, :, :].numpy()            # Original image
    gt_mask = gt[0].numpy()                   # Ground truth mask
    # Threshold prediction (it might still be probabilities)
    pred_mask = (pred[0] > 0.5).float().numpy()
    
    # Original image
    axes[i, 0].imshow(img, cmap="gray")
    axes[i, 0].set_title("Original Image")
    axes[i, 0].axis("off")
    
    # Ground truth overlay
    axes[i, 1].imshow(img, cmap="gray")
    axes[i, 1].imshow(gt_mask, cmap="jet", alpha=0.5)
    axes[i, 1].set_title("Ground Truth")
    axes[i, 1].axis("off")
    
    # Prediction overlay with Dice score
    axes[i, 2].imshow(img, cmap="gray")
    axes[i, 2].imshow(pred_mask, cmap="jet", alpha=0.5)
    axes[i, 2].set_title(fr"Prediction (Dice: {dice:.4f})")
    axes[i, 2].axis("off")
    
plt.tight_layout()
plt.show()




